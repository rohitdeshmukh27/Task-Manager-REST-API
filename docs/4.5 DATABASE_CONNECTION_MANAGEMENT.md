# ğŸ—„ï¸ Database & Connection Management - Complete Practice Guide

## ğŸ“‹ Level 2.5: Master Your Database Layer

Practice **hands-on database and connection management** for your Task Manager API:

- **Connection Pooling** - Efficient database connections
- **Supabase Client Patterns** - Singleton, service key, admin client
- **Database Migrations** - Version-controlled schema changes
- **Transactions** - Atomic multi-step operations
- **Query Optimization** - Indexes, EXPLAIN, performance tuning
- **Error Handling** - Graceful database failure recovery
- **Health Checks** - Monitor database connectivity

**Time to Complete:** 4-5 hours

---

# ğŸ¯ Why Database Management Matters?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABASE MANAGEMENT VALUE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ğŸ”— CONNECTION MANAGEMENT:                                      â”‚
â”‚  â€¢ Prevent connection leaks & timeouts                          â”‚
â”‚  â€¢ Handle concurrent requests efficiently                       â”‚
â”‚  â€¢ Auto-reconnect on failures                                   â”‚
â”‚                                                                  â”‚
â”‚  ğŸ“¦ MIGRATIONS:                                                 â”‚
â”‚  â€¢ Track schema changes in version control                      â”‚
â”‚  â€¢ Rollback broken deployments                                  â”‚
â”‚  â€¢ Team collaboration on DB changes                             â”‚
â”‚                                                                  â”‚
â”‚  âš¡ QUERY OPTIMIZATION:                                         â”‚
â”‚  â€¢ 10x-100x faster queries with indexes                         â”‚
â”‚  â€¢ Avoid N+1 query problems                                     â”‚
â”‚  â€¢ Reduce database load & costs                                 â”‚
â”‚                                                                  â”‚
â”‚  ğŸ›¡ï¸ ERROR HANDLING:                                              â”‚
â”‚  â€¢ Graceful degradation on DB failures                           â”‚
â”‚  â€¢ Retry logic for transient errors                             â”‚
â”‚  â€¢ Connection timeout management                                 â”‚
â”‚                                                                  â”‚
â”‚  ğŸ”„ TRANSACTIONS:                                               â”‚
â”‚  â€¢ Ensure data consistency                                       â”‚
â”‚  â€¢ Atomic multi-table operations                                â”‚
â”‚  â€¢ Prevent partial updates                                       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ—ï¸ What You'll Build

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABASE LAYER ARCHITECTURE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Express App    â”‚
                    â”‚    (app.ts)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Service Layer   â”‚
                    â”‚ (taskService.ts) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  Supabase  â”‚  â”‚  Database  â”‚  â”‚   Query     â”‚
    â”‚  Client    â”‚  â”‚  Health    â”‚  â”‚  Optimizer  â”‚
    â”‚ (Singleton)â”‚  â”‚  Monitor   â”‚  â”‚  (Indexes)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚              â”‚              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  â˜ï¸ Supabase     â”‚
                    â”‚  PostgreSQL DB   â”‚
                    â”‚  (Connection     â”‚
                    â”‚   Pool: 20-50)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ› ï¸ STEP-BY-STEP IMPLEMENTATION

---

## PHASE 1: UNDERSTANDING DATABASE CONNECTIONS

---

### STEP 1: How Supabase Connections Work

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONNECTION FLOW                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Your App â”€â”€â–º Supabase Client â”€â”€â–º PostgREST API â”€â”€â–º PostgreSQL  â”‚
â”‚                                                                  â”‚
â”‚  Unlike traditional databases, Supabase uses:                    â”‚
â”‚                                                                  â”‚
â”‚  1. REST API (PostgREST) - Default, auto-managed pooling        â”‚
â”‚  2. Direct Connection - For advanced queries/transactions        â”‚
â”‚  3. Connection Pooler (PgBouncer) - For serverless/edge         â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   REST API  â”‚     â”‚   Direct    â”‚     â”‚  PgBouncer  â”‚       â”‚
â”‚  â”‚  Port 443   â”‚     â”‚  Port 5432  â”‚     â”‚  Port 6543  â”‚       â”‚
â”‚  â”‚  (Default)  â”‚     â”‚ (Advanced)  â”‚     â”‚ (Serverless)â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’¡ Connection Types Explained:

| Type | Port | Use Case | Pooling |
|------|------|----------|---------|
| **REST API** | 443 | Standard CRUD operations | Auto-managed |
| **Direct** | 5432 | Migrations, complex queries | Manual |
| **PgBouncer** | 6543 | Serverless, high concurrency | Transaction mode |

---

### STEP 2: Enhanced Supabase Client Configuration

ğŸ“ **File:** `src/config/supabase.ts` (Enhanced Version)

```typescript
// ============================================
// SUPABASE CLIENT - Enhanced Configuration
// ============================================

import { createClient, SupabaseClient } from "@supabase/supabase-js";
import dotenv from "dotenv";

// Load environment variables
dotenv.config();

// ============================================
// ENVIRONMENT VALIDATION
// ============================================

interface SupabaseConfig {
  url: string;
  anonKey: string;
  serviceRoleKey?: string; // For admin operations
}

const getConfig = (): SupabaseConfig => {
  const url = process.env.SUPABASE_URL;
  const anonKey = process.env.SUPABASE_ANON_KEY;
  const serviceRoleKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

  if (!url || !anonKey) {
    console.error("âŒ Missing required Supabase environment variables!");
    console.error("Required: SUPABASE_URL, SUPABASE_ANON_KEY");
    process.exit(1);
  }

  return { url, anonKey, serviceRoleKey };
};

// ============================================
// SINGLETON PATTERN - Single Client Instance
// ============================================

/**
 * WHY SINGLETON?
 * 
 * âŒ BAD: Creating new client on every request
 *    â†’ Each request creates new HTTP connection
 *    â†’ Memory leaks, connection exhaustion
 * 
 * âœ… GOOD: Single client instance shared across app
 *    â†’ Reuses HTTP connections
 *    â†’ Efficient memory usage
 *    â†’ Consistent configuration
 */

let supabaseInstance: SupabaseClient | null = null;

const createSupabaseClient = (): SupabaseClient => {
  if (supabaseInstance) {
    return supabaseInstance; // Return existing instance
  }

  const config = getConfig();

  supabaseInstance = createClient(config.url, config.anonKey, {
    auth: {
      autoRefreshToken: true,       // Auto-refresh JWT tokens
      persistSession: false,        // Server-side: no session persistence
      detectSessionInUrl: false,    // Server-side: no URL detection
    },
    db: {
      schema: "public",             // Default schema
    },
    global: {
      headers: {
        "x-application-name": "task-manager-api", // Identify your app
      },
    },
  });

  console.log("âœ… Supabase client initialized (Singleton)");
  console.log(`ğŸ“ Connected to: ${config.url}`);

  return supabaseInstance;
};

// Export singleton instance
const supabase = createSupabaseClient();
export default supabase;

// ============================================
// ADMIN CLIENT (Service Role - Bypasses RLS)
// ============================================

/**
 * Use this ONLY for admin operations that need
 * to bypass Row Level Security (RLS).
 * 
 * âš ï¸ NEVER expose service role key to client!
 * âš ï¸ ONLY use in trusted server-side code!
 */

let adminClientInstance: SupabaseClient | null = null;

export const getAdminClient = (): SupabaseClient | null => {
  const config = getConfig();

  if (!config.serviceRoleKey) {
    console.warn("âš ï¸ SUPABASE_SERVICE_ROLE_KEY not set - admin client unavailable");
    return null;
  }

  if (adminClientInstance) {
    return adminClientInstance;
  }

  adminClientInstance = createClient(config.url, config.serviceRoleKey, {
    auth: {
      autoRefreshToken: false,
      persistSession: false,
    },
  });

  console.log("âœ… Supabase admin client initialized");
  return adminClientInstance;
};

// ============================================
// CONNECTION HEALTH CHECK
// ============================================

/**
 * Test database connectivity
 * Use in health check endpoints and startup validation
 */
export const checkDatabaseHealth = async (): Promise<{
  connected: boolean;
  latencyMs: number;
  error?: string;
}> => {
  const startTime = Date.now();

  try {
    // Simple query to test connectivity
    const { data, error } = await supabase
      .from("tasks")
      .select("count", { count: "exact", head: true });

    const latencyMs = Date.now() - startTime;

    if (error) {
      return {
        connected: false,
        latencyMs,
        error: error.message,
      };
    }

    return {
      connected: true,
      latencyMs,
    };
  } catch (err) {
    return {
      connected: false,
      latencyMs: Date.now() - startTime,
      error: err instanceof Error ? err.message : "Unknown error",
    };
  }
};
```

### ğŸ’¡ Singleton Pattern - Visual Explanation:

```
WITHOUT SINGLETON (âŒ BAD):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Request 1 â”‚â”€â”€â”€â”€â–ºâ”‚ New Client 1 â”‚â”€â”€â–º DB Connection 1
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Request 2 â”‚â”€â”€â”€â”€â–ºâ”‚ New Client 2 â”‚â”€â”€â–º DB Connection 2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Request 3 â”‚â”€â”€â”€â”€â–ºâ”‚ New Client 3 â”‚â”€â”€â–º DB Connection 3
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Result: 100 requests = 100 connections = ğŸ’€ Connection exhaustion!

WITH SINGLETON (âœ… GOOD):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Request 1 â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”œâ”€â”€â–ºâ”‚ Single Client    â”‚â”€â”€â–º 1 Connection (pooled)
â”‚ Request 2 â”‚â”€â”€â”¤   â”‚ (Shared Instance)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ Request 3 â”‚â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Result: 100 requests = 1 client = âœ… Efficient!
```

---

## PHASE 2: DATABASE ERROR HANDLING

---

### STEP 3: Create Database Error Handler

ğŸ“ **File:** `src/config/dbErrorHandler.ts` (New file)

```typescript
// ============================================
// DATABASE ERROR HANDLER
// ============================================

/**
 * PostgreSQL error codes we care about
 * Full list: https://www.postgresql.org/docs/current/errcodes-appendix.html
 */
export enum PgErrorCode {
  // Connection errors
  CONNECTION_FAILURE = "08006",
  CONNECTION_EXCEPTION = "08000",

  // Integrity violations
  UNIQUE_VIOLATION = "23505",
  FOREIGN_KEY_VIOLATION = "23503",
  NOT_NULL_VIOLATION = "23502",
  CHECK_VIOLATION = "23514",

  // Data errors
  INVALID_TEXT_REPRESENTATION = "22P02",
  STRING_DATA_RIGHT_TRUNCATION = "22001",

  // Permission errors
  INSUFFICIENT_PRIVILEGE = "42501",

  // Resource errors
  TOO_MANY_CONNECTIONS = "53300",
  DISK_FULL = "53100",
}

/**
 * Supabase/PostgREST error codes
 */
export enum SupabaseErrorCode {
  NO_ROWS_FOUND = "PGRST116",
  JWT_EXPIRED = "PGRST301",
  INVALID_JWT = "PGRST302",
}

// ============================================
// ERROR TYPES
// ============================================

export interface DatabaseError {
  code: string;
  message: string;
  detail?: string;
  hint?: string;
  statusCode: number; // HTTP status to return
}

// ============================================
// ERROR PARSER
// ============================================

/**
 * Parse database errors into user-friendly messages
 * Maps PostgreSQL error codes to HTTP status codes
 */
export const parseDatabaseError = (error: any): DatabaseError => {
  const code = error?.code || "UNKNOWN";
  const message = error?.message || "An unexpected database error occurred";
  const detail = error?.details || error?.detail;
  const hint = error?.hint;

  // â”€â”€ Connection Errors â”€â”€
  if (
    code === PgErrorCode.CONNECTION_FAILURE ||
    code === PgErrorCode.CONNECTION_EXCEPTION
  ) {
    return {
      code,
      message: "Database connection failed. Please try again later.",
      detail,
      hint: "The database may be temporarily unavailable",
      statusCode: 503, // Service Unavailable
    };
  }

  // â”€â”€ Unique Violation (duplicate) â”€â”€
  if (code === PgErrorCode.UNIQUE_VIOLATION) {
    // Extract field name from detail
    const field = extractFieldFromDetail(detail);
    return {
      code,
      message: `A record with this ${field || "value"} already exists.`,
      detail,
      hint: `Try a different ${field || "value"}`,
      statusCode: 409, // Conflict
    };
  }

  // â”€â”€ Foreign Key Violation â”€â”€
  if (code === PgErrorCode.FOREIGN_KEY_VIOLATION) {
    return {
      code,
      message: "Referenced record not found.",
      detail,
      hint: "Ensure the related record exists before referencing it",
      statusCode: 400,
    };
  }

  // â”€â”€ Not Null Violation â”€â”€
  if (code === PgErrorCode.NOT_NULL_VIOLATION) {
    const field = extractFieldFromDetail(detail);
    return {
      code,
      message: `The field '${field || "unknown"}' is required.`,
      detail,
      hint: `Provide a value for '${field}'`,
      statusCode: 400,
    };
  }

  // â”€â”€ Check Constraint Violation â”€â”€
  if (code === PgErrorCode.CHECK_VIOLATION) {
    return {
      code,
      message: "Invalid value provided.",
      detail,
      hint: "Check the allowed values for this field",
      statusCode: 400,
    };
  }

  // â”€â”€ No Rows Found (Supabase) â”€â”€
  if (code === SupabaseErrorCode.NO_ROWS_FOUND) {
    return {
      code,
      message: "Record not found.",
      statusCode: 404,
    };
  }

  // â”€â”€ Too Many Connections â”€â”€
  if (code === PgErrorCode.TOO_MANY_CONNECTIONS) {
    return {
      code,
      message: "Server is busy. Please try again in a moment.",
      detail,
      hint: "Connection pool exhausted",
      statusCode: 503,
    };
  }

  // â”€â”€ Default: Unknown Error â”€â”€
  return {
    code,
    message: "A database error occurred.",
    detail: process.env.NODE_ENV === "development" ? message : undefined,
    statusCode: 500,
  };
};

// ============================================
// HELPER: Extract field name from PG error detail
// ============================================

const extractFieldFromDetail = (detail?: string): string | null => {
  if (!detail) return null;

  // Pattern: Key (field_name)=(value) already exists
  const match = detail.match(/Key \((\w+)\)/);
  return match ? match[1] : null;
};

// ============================================
// RETRY LOGIC FOR TRANSIENT ERRORS
// ============================================

/**
 * Retry a database operation with exponential backoff
 * Use for transient errors like connection timeouts
 * 
 * @example
 * const result = await retryOperation(
 *   () => supabase.from('tasks').select('*'),
 *   { maxRetries: 3, baseDelayMs: 1000 }
 * );
 */
export const retryOperation = async <T>(
  operation: () => Promise<T>,
  options: {
    maxRetries?: number;
    baseDelayMs?: number;
    maxDelayMs?: number;
  } = {}
): Promise<T> => {
  const { maxRetries = 3, baseDelayMs = 1000, maxDelayMs = 10000 } = options;

  let lastError: any;

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error: any) {
      lastError = error;

      // Don't retry non-transient errors
      if (!isTransientError(error)) {
        throw error;
      }

      // Don't wait after last attempt
      if (attempt < maxRetries) {
        const delay = Math.min(
          baseDelayMs * Math.pow(2, attempt), // Exponential backoff
          maxDelayMs
        );
        console.warn(
          `âš ï¸ DB operation failed (attempt ${attempt + 1}/${maxRetries + 1}). ` +
          `Retrying in ${delay}ms...`
        );
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
  }

  throw lastError;
};

/**
 * Check if an error is transient (worth retrying)
 */
const isTransientError = (error: any): boolean => {
  const transientCodes = [
    PgErrorCode.CONNECTION_FAILURE,
    PgErrorCode.CONNECTION_EXCEPTION,
    PgErrorCode.TOO_MANY_CONNECTIONS,
  ];

  return (
    transientCodes.includes(error?.code) ||
    error?.message?.includes("timeout") ||
    error?.message?.includes("ECONNRESET") ||
    error?.message?.includes("ECONNREFUSED")
  );
};
```

### ğŸ’¡ Retry with Exponential Backoff - Visual:

```
Attempt 1: Failed â†’ Wait 1000ms  (1s)
Attempt 2: Failed â†’ Wait 2000ms  (2s)
Attempt 3: Failed â†’ Wait 4000ms  (4s)
Attempt 4: Success âœ… (or throw final error)

WHY EXPONENTIAL?
â€¢ Gives the database time to recover
â€¢ Prevents "thundering herd" problem
â€¢ Each retry waits longer, reducing pressure
```

---

## PHASE 3: DATABASE HEALTH MONITORING

---

### STEP 4: Create Health Check Route

ğŸ“ **File:** `src/routes/healthRoutes.ts` (New or Update)

```typescript
// ============================================
// DATABASE HEALTH CHECK ROUTES
// ============================================

import { Router, Request, Response } from "express";
import { checkDatabaseHealth } from "../config/supabase";

const router = Router();

/**
 * GET /health
 * Basic health check - is the server running?
 */
router.get("/", (req: Request, res: Response) => {
  res.status(200).json({
    success: true,
    status: "healthy",
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
  });
});

/**
 * GET /health/db
 * Database health check - is the DB accessible?
 * 
 * Response includes:
 *  - connected: boolean (is DB reachable?)
 *  - latencyMs: number (round-trip time)
 *  - status: 'healthy' | 'degraded' | 'unhealthy'
 */
router.get("/db", async (req: Request, res: Response) => {
  const health = await checkDatabaseHealth();

  // Determine status based on latency
  let status: "healthy" | "degraded" | "unhealthy";
  if (!health.connected) {
    status = "unhealthy";
  } else if (health.latencyMs > 1000) {
    status = "degraded"; // Connected but slow
  } else {
    status = "healthy";
  }

  const statusCode = status === "unhealthy" ? 503 : 200;

  res.status(statusCode).json({
    success: health.connected,
    status,
    database: {
      connected: health.connected,
      latencyMs: health.latencyMs,
      error: health.error || null,
    },
    timestamp: new Date().toISOString(),
    thresholds: {
      healthy: "< 1000ms",
      degraded: "> 1000ms",
      unhealthy: "Connection failed",
    },
  });
});

/**
 * GET /health/detailed
 * Detailed system health (memory, uptime, db)
 */
router.get("/detailed", async (req: Request, res: Response) => {
  const dbHealth = await checkDatabaseHealth();
  const memUsage = process.memoryUsage();

  res.status(200).json({
    success: true,
    system: {
      uptime: process.uptime(),
      nodeVersion: process.version,
      environment: process.env.NODE_ENV || "development",
      memory: {
        heapUsed: `${Math.round(memUsage.heapUsed / 1024 / 1024)}MB`,
        heapTotal: `${Math.round(memUsage.heapTotal / 1024 / 1024)}MB`,
        rss: `${Math.round(memUsage.rss / 1024 / 1024)}MB`,
      },
    },
    database: {
      connected: dbHealth.connected,
      latencyMs: dbHealth.latencyMs,
      error: dbHealth.error || null,
    },
    timestamp: new Date().toISOString(),
  });
});

export default router;
```

### STEP 5: Mount Health Routes in App

ğŸ“ **File:** `src/app.ts` (Add this)

```typescript
// Add this import at the top
import healthRoutes from "./routes/healthRoutes";

// Mount health routes BEFORE other middleware
// (health checks should bypass auth & rate limiting)
app.use("/health", healthRoutes);
```

### STEP 6: Test Health Endpoints

```bash
# Test basic health
curl http://localhost:3000/health

# Test database health
curl http://localhost:3000/health/db

# Test detailed health (includes memory usage)
curl http://localhost:3000/health/detailed
```

Expected responses:

```json
// GET /health/db (Healthy)
{
  "success": true,
  "status": "healthy",
  "database": {
    "connected": true,
    "latencyMs": 45,
    "error": null
  },
  "timestamp": "2026-02-10T11:00:00.000Z"
}

// GET /health/db (Unhealthy - DB down)
{
  "success": false,
  "status": "unhealthy",
  "database": {
    "connected": false,
    "latencyMs": 5000,
    "error": "Connection timed out"
  }
}
```

---

## PHASE 4: DATABASE MIGRATIONS

---

### STEP 7: Understanding Migrations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABASE MIGRATIONS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  âŒ WITHOUT MIGRATIONS:                                         â”‚
â”‚  â€¢ "Hey, did you run the ALTER TABLE?"                          â”‚
â”‚  â€¢ "My local DB doesn't have that column"                       â”‚
â”‚  â€¢ "Who changed the schema?"                                    â”‚
â”‚  â€¢ "Can we rollback? I don't remember the old schema"          â”‚
â”‚                                                                  â”‚
â”‚  âœ… WITH MIGRATIONS:                                            â”‚
â”‚  â€¢ Every schema change is versioned                             â”‚
â”‚  â€¢ Team members run same migrations                             â”‚
â”‚  â€¢ Easy rollback to previous version                            â”‚
â”‚  â€¢ Schema changes tracked in Git                                â”‚
â”‚                                                                  â”‚
â”‚  MIGRATION FLOW:                                                â”‚
â”‚  v001_create_tasks.sql â”€â”€â–º v002_add_priority.sql â”€â”€â–º           â”‚
â”‚  v003_add_user_id.sql  â”€â”€â–º v004_create_tags.sql                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### STEP 8: Create Migration System

Create a `migrations/` folder for SQL files:

```bash
mkdir migrations
```

ğŸ“ **File:** `migrations/001_create_tasks_table.sql`

```sql
-- =============================================
-- MIGRATION 001: Create Tasks Table
-- Date: 2026-02-10
-- Description: Initial tasks table creation
-- =============================================

-- UP MIGRATION (Apply)
-- =============================================

CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

CREATE TABLE IF NOT EXISTS tasks (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    status VARCHAR(50) DEFAULT 'pending'
        CHECK (status IN ('pending', 'in-progress', 'completed')),
    priority VARCHAR(50) DEFAULT 'medium'
        CHECK (priority IN ('low', 'medium', 'high')),
    due_date TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for common queries
CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks(status);
CREATE INDEX IF NOT EXISTS idx_tasks_priority ON tasks(priority);
CREATE INDEX IF NOT EXISTS idx_tasks_created_at ON tasks(created_at DESC);

-- Auto-update trigger for updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

DROP TRIGGER IF EXISTS update_tasks_updated_at ON tasks;
CREATE TRIGGER update_tasks_updated_at
    BEFORE UPDATE ON tasks
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- =============================================
-- DOWN MIGRATION (Rollback) - Run if you need to undo
-- =============================================
-- DROP TRIGGER IF EXISTS update_tasks_updated_at ON tasks;
-- DROP FUNCTION IF EXISTS update_updated_at_column();
-- DROP TABLE IF EXISTS tasks;
```

ğŸ“ **File:** `migrations/002_add_user_id.sql`

```sql
-- =============================================
-- MIGRATION 002: Add User ID to Tasks
-- Date: 2026-02-10
-- Description: Link tasks to authenticated users
-- =============================================

-- UP MIGRATION
-- =============================================

ALTER TABLE tasks
ADD COLUMN IF NOT EXISTS user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE;

CREATE INDEX IF NOT EXISTS idx_tasks_user_id ON tasks(user_id);

-- Enable Row Level Security
ALTER TABLE tasks ENABLE ROW LEVEL SECURITY;

-- RLS Policies
CREATE POLICY "Users can view own tasks" ON tasks
    FOR SELECT USING (auth.uid() = user_id);

CREATE POLICY "Users can create own tasks" ON tasks
    FOR INSERT WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update own tasks" ON tasks
    FOR UPDATE USING (auth.uid() = user_id)
    WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can delete own tasks" ON tasks
    FOR DELETE USING (auth.uid() = user_id);

-- =============================================
-- DOWN MIGRATION (Rollback)
-- =============================================
-- DROP POLICY IF EXISTS "Users can delete own tasks" ON tasks;
-- DROP POLICY IF EXISTS "Users can update own tasks" ON tasks;
-- DROP POLICY IF EXISTS "Users can create own tasks" ON tasks;
-- DROP POLICY IF EXISTS "Users can view own tasks" ON tasks;
-- ALTER TABLE tasks DISABLE ROW LEVEL SECURITY;
-- ALTER TABLE tasks DROP COLUMN IF EXISTS user_id;
```

ğŸ“ **File:** `migrations/003_create_tags.sql`

```sql
-- =============================================
-- MIGRATION 003: Create Tags System
-- Date: 2026-02-10
-- Description: Tags and many-to-many relationship
-- =============================================

-- UP MIGRATION
-- =============================================

-- Tags table
CREATE TABLE IF NOT EXISTS tags (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    name VARCHAR(50) NOT NULL,
    color VARCHAR(7) DEFAULT '#6366f1',
    user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(name, user_id)
);

CREATE INDEX IF NOT EXISTS idx_tags_user_id ON tags(user_id);

-- Junction table (many-to-many: tasks <-> tags)
CREATE TABLE IF NOT EXISTS task_tags (
    task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
    tag_id UUID NOT NULL REFERENCES tags(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    PRIMARY KEY (task_id, tag_id)
);

CREATE INDEX IF NOT EXISTS idx_task_tags_task_id ON task_tags(task_id);
CREATE INDEX IF NOT EXISTS idx_task_tags_tag_id ON task_tags(tag_id);

-- RLS for tags
ALTER TABLE tags ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can manage own tags" ON tags
    FOR ALL USING (auth.uid() = user_id);

-- =============================================
-- DOWN MIGRATION (Rollback)
-- =============================================
-- DROP TABLE IF EXISTS task_tags;
-- DROP TABLE IF EXISTS tags;
```

### ğŸ’¡ Migration Best Practices:

| Rule | Why |
|------|-----|
| **Number sequentially** | `001`, `002`, `003` ensures order |
| **Never edit old migrations** | Create a new one instead |
| **Include DOWN migration** | Always have rollback plan |
| **Test on dev first** | Never run untested SQL in production |
| **One concern per migration** | Easier to debug and rollback |

---

## PHASE 5: TRANSACTIONS

---

### STEP 9: Understanding Transactions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRANSACTIONS                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  A transaction groups multiple operations into ONE atomic unit.  â”‚
â”‚  Either ALL operations succeed, or NONE of them do.             â”‚
â”‚                                                                  â”‚
â”‚  EXAMPLE: Create task + Assign tags                             â”‚
â”‚                                                                  â”‚
â”‚  WITHOUT Transaction:                                            â”‚
â”‚  Step 1: Insert task     âœ… Success                             â”‚
â”‚  Step 2: Insert tag      âœ… Success                             â”‚
â”‚  Step 3: Link task-tag   âŒ FAILS!                              â”‚
â”‚  Result: Orphaned task and tag in DB ğŸ˜±                         â”‚
â”‚                                                                  â”‚
â”‚  WITH Transaction:                                               â”‚
â”‚  BEGIN TRANSACTION                                               â”‚
â”‚  Step 1: Insert task     âœ…                                     â”‚
â”‚  Step 2: Insert tag      âœ…                                     â”‚
â”‚  Step 3: Link task-tag   âŒ FAILS!                              â”‚
â”‚  ROLLBACK â†’ All 3 steps undone âœ…                               â”‚
â”‚  Result: Clean database, no orphaned data ğŸ‰                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### STEP 10: Implement Transactions with Supabase

ğŸ“ **File:** `src/services/transactionService.ts` (New file)

```typescript
// ============================================
// TRANSACTION SERVICE - Atomic Operations
// ============================================

import supabase from "../config/supabase";

/**
 * Create a task with tags in a single transaction
 * 
 * Uses Supabase's RPC (Remote Procedure Call) to execute
 * a PostgreSQL function that wraps everything in a transaction.
 */

// ============================================
// STEP 1: Create the SQL function first!
// Run this in Supabase SQL Editor:
// ============================================

/*
CREATE OR REPLACE FUNCTION create_task_with_tags(
    p_title VARCHAR,
    p_description TEXT,
    p_priority VARCHAR,
    p_due_date TIMESTAMP WITH TIME ZONE,
    p_user_id UUID,
    p_tag_ids UUID[]
)
RETURNS JSON
LANGUAGE plpgsql
AS $$
DECLARE
    v_task_id UUID;
    v_task JSON;
    v_tag_id UUID;
BEGIN
    -- Step 1: Create the task
    INSERT INTO tasks (title, description, priority, due_date, user_id, status)
    VALUES (p_title, p_description, p_priority, p_due_date, p_user_id, 'pending')
    RETURNING id INTO v_task_id;

    -- Step 2: Link tags to the task
    IF p_tag_ids IS NOT NULL THEN
        FOREACH v_tag_id IN ARRAY p_tag_ids
        LOOP
            INSERT INTO task_tags (task_id, tag_id)
            VALUES (v_task_id, v_tag_id);
        END LOOP;
    END IF;

    -- Step 3: Return the complete task with tags
    SELECT json_build_object(
        'id', t.id,
        'title', t.title,
        'description', t.description,
        'status', t.status,
        'priority', t.priority,
        'due_date', t.due_date,
        'user_id', t.user_id,
        'created_at', t.created_at,
        'tags', COALESCE(
            (SELECT json_agg(json_build_object(
                'id', tg.id,
                'name', tg.name,
                'color', tg.color
            ))
            FROM task_tags tt
            JOIN tags tg ON tg.id = tt.tag_id
            WHERE tt.task_id = t.id),
            '[]'::json
        )
    ) INTO v_task
    FROM tasks t
    WHERE t.id = v_task_id;

    RETURN v_task;
END;
$$;
*/

// ============================================
// STEP 2: Call the function from TypeScript
// ============================================

interface CreateTaskWithTagsDTO {
  title: string;
  description?: string;
  priority?: string;
  due_date?: string;
  tag_ids?: string[];
}

export const createTaskWithTags = async (
  taskData: CreateTaskWithTagsDTO,
  userId: string
) => {
  const { data, error } = await supabase.rpc("create_task_with_tags", {
    p_title: taskData.title,
    p_description: taskData.description || null,
    p_priority: taskData.priority || "medium",
    p_due_date: taskData.due_date || null,
    p_user_id: userId,
    p_tag_ids: taskData.tag_ids || [],
  });

  if (error) {
    console.error("âŒ Transaction failed:", error.message);
    return { data: null, error };
  }

  console.log("âœ… Task created with tags (atomic transaction)");
  return { data, error: null };
};

// ============================================
// BATCH OPERATIONS (Multiple tasks at once)
// ============================================

/**
 * Update multiple tasks' status at once
 * Useful for "Mark all as completed" feature
 */
export const batchUpdateTaskStatus = async (
  taskIds: string[],
  newStatus: string,
  userId: string
) => {
  const { data, error } = await supabase
    .from("tasks")
    .update({ status: newStatus })
    .in("id", taskIds)           // WHERE id IN (...)
    .eq("user_id", userId)        // AND user_id = ...
    .select();

  return { data, error, count: data?.length || 0 };
};

/**
 * Delete multiple tasks at once
 */
export const batchDeleteTasks = async (
  taskIds: string[],
  userId: string
) => {
  const { error } = await supabase
    .from("tasks")
    .delete()
    .in("id", taskIds)
    .eq("user_id", userId);

  return { error, deletedCount: error ? 0 : taskIds.length };
};
```

---

## PHASE 6: QUERY OPTIMIZATION

---

### STEP 11: Understanding Indexes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INDEXES EXPLAINED                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  WITHOUT INDEX (Full Table Scan):                                â”‚
â”‚  "Find tasks with status = 'pending'"                           â”‚
â”‚  â†’ Scan ALL 10,000 rows one by one                              â”‚
â”‚  â†’ Time: ~100ms                                                  â”‚
â”‚                                                                  â”‚
â”‚  WITH INDEX (Index Lookup):                                      â”‚
â”‚  "Find tasks with status = 'pending'"                           â”‚
â”‚  â†’ Jump directly to matching rows                               â”‚
â”‚  â†’ Time: ~2ms (50x faster!)                                     â”‚
â”‚                                                                  â”‚
â”‚  ANALOGY:                                                        â”‚
â”‚  ğŸ“– Book without index: Read every page to find a topic         â”‚
â”‚  ğŸ“– Book with index: Look up page number, go directly there    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### STEP 12: Create Optimized Indexes

Run this SQL in Supabase SQL Editor:

```sql
-- =============================================
-- QUERY OPTIMIZATION: Indexes
-- =============================================

-- 1. Composite index for common filter combinations
-- Used when: GET /tasks?status=pending&priority=high
CREATE INDEX IF NOT EXISTS idx_tasks_status_priority
ON tasks(status, priority);

-- 2. Partial index (only index pending tasks)
-- Used when: Frequent queries for pending tasks only
CREATE INDEX IF NOT EXISTS idx_tasks_pending
ON tasks(created_at DESC)
WHERE status = 'pending';

-- 3. Text search index for title searching
-- Used when: GET /tasks?search=typescript
CREATE INDEX IF NOT EXISTS idx_tasks_title_search
ON tasks USING gin(to_tsvector('english', title));

-- 4. Index for due date queries (upcoming tasks)
-- Used when: "Show tasks due this week"
CREATE INDEX IF NOT EXISTS idx_tasks_due_date
ON tasks(due_date)
WHERE due_date IS NOT NULL;

-- 5. Composite index for user + status (most common query)
-- Used when: "Show MY pending tasks"
CREATE INDEX IF NOT EXISTS idx_tasks_user_status
ON tasks(user_id, status);
```

### STEP 13: Analyze Query Performance

```sql
-- =============================================
-- ANALYZE QUERY PERFORMANCE
-- =============================================

-- Check if your index is being used
EXPLAIN ANALYZE
SELECT * FROM tasks
WHERE status = 'pending' AND priority = 'high';

-- Expected output with index:
-- Index Scan using idx_tasks_status_priority on tasks
-- Actual rows=5, loops=1
-- Planning Time: 0.1ms
-- Execution Time: 0.05ms â† FAST!

-- Check without index (for comparison):
-- Seq Scan on tasks
-- Actual rows=5, loops=1
-- Planning Time: 0.1ms
-- Execution Time: 2.5ms â† 50x SLOWER!

-- =============================================
-- VIEW ALL INDEXES ON A TABLE
-- =============================================

SELECT
    indexname,
    indexdef
FROM pg_indexes
WHERE tablename = 'tasks'
ORDER BY indexname;

-- =============================================
-- CHECK INDEX SIZE & USAGE
-- =============================================

SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexname::regclass)) AS index_size,
    idx_scan AS times_used,
    idx_tup_read AS rows_read
FROM pg_stat_user_indexes
WHERE tablename = 'tasks'
ORDER BY idx_scan DESC;
```

### ğŸ’¡ When to Index (and When NOT to):

| âœ… Index When | âŒ Don't Index When |
|---|---|
| Column used in WHERE clauses | Table has < 1000 rows |
| Column used in JOIN conditions | Column rarely queried |
| Column used in ORDER BY | Column has very few unique values |
| High-read, low-write tables | Table has heavy INSERT/UPDATE |

---

## PHASE 7: PRACTICE EXERCISES

---

### ğŸ‹ï¸ Exercise 1: Connection Health Dashboard

**Goal:** Build a `/health/dashboard` endpoint that returns detailed DB info.

```typescript
// TODO: Create an endpoint that returns:
// 1. Database connection status
// 2. Current latency
// 3. Number of tasks in DB
// 4. Number of users in DB
// 5. Last task created timestamp
// 6. Server uptime

// Hints:
// - Use checkDatabaseHealth() for connection
// - Use supabase.from('tasks').select('count', { count: 'exact', head: true })
// - Use process.uptime() for uptime
```

**Expected Response:**
```json
{
  "database": {
    "status": "healthy",
    "latencyMs": 42,
    "taskCount": 156,
    "userCount": 12,
    "lastTaskCreated": "2026-02-10T10:30:00Z"
  },
  "server": {
    "uptime": "2h 35m",
    "nodeVersion": "v20.11.0",
    "environment": "development"
  }
}
```

---

### ğŸ‹ï¸ Exercise 2: Implement Retry Logic in Task Service

**Goal:** Wrap your `getAllTasks` with retry logic.

```typescript
// TODO: Update taskService.ts to use retryOperation
// for database calls that might have transient failures

import { retryOperation } from "../config/dbErrorHandler";

export const getAllTasks = async (params: TaskQueryParams) => {
  return retryOperation(async () => {
    // Your existing getAllTasks logic here
    let query = supabase.from("tasks").select("*", { count: "exact" });
    // ... filters, sorting, pagination
    const { data, error, count } = await query;
    
    if (error) throw error; // Trigger retry for transient errors
    return { data, error: null, count };
  }, {
    maxRetries: 3,
    baseDelayMs: 500,
  });
};
```

---

### ğŸ‹ï¸ Exercise 3: Create a Migration

**Goal:** Write migration `004_add_task_notes.sql` that adds a `notes` JSONB column.

```sql
-- TODO: Create migration that:
-- 1. Adds a 'notes' column (JSONB type, default empty array)
-- 2. Adds a GIN index for searching within notes
-- 3. Include DOWN migration for rollback

-- Hints:
-- JSONB stores JSON data efficiently in PostgreSQL
-- GIN index allows fast searching within JSON
-- Example: ALTER TABLE tasks ADD COLUMN notes JSONB DEFAULT '[]'::jsonb;
```

---

### ğŸ‹ï¸ Exercise 4: Query Optimization Challenge

**Goal:** Run `EXPLAIN ANALYZE` on 3 queries and optimize them.

```sql
-- Query 1: Find all pending high-priority tasks (ordered by due date)
EXPLAIN ANALYZE
SELECT * FROM tasks
WHERE status = 'pending' AND priority = 'high'
ORDER BY due_date ASC;

-- Query 2: Search tasks by title (case-insensitive)
EXPLAIN ANALYZE
SELECT * FROM tasks
WHERE title ILIKE '%typescript%';

-- Query 3: Count tasks per status for a specific user
EXPLAIN ANALYZE
SELECT status, COUNT(*)
FROM tasks
WHERE user_id = 'your-user-id'
GROUP BY status;

-- TODO: For each query:
-- 1. Note the execution time WITHOUT indexes
-- 2. Create appropriate indexes
-- 3. Run EXPLAIN ANALYZE again
-- 4. Compare the improvement!
```

---

## ğŸ“ SUMMARY CHECKLIST

| Phase | Topic | Status |
|-------|-------|--------|
| 1 | Enhanced Supabase Client (Singleton) | â¬œ |
| 2 | Database Error Handler with Retry | â¬œ |
| 3 | Health Check Endpoints | â¬œ |
| 4 | Migration System Setup | â¬œ |
| 5 | Transactions with RPC | â¬œ |
| 6 | Query Optimization & Indexes | â¬œ |
| 7 | Practice Exercises | â¬œ |

---

## ğŸ”— Quick Reference

### Supabase Dashboard Locations:
- **SQL Editor:** Dashboard â†’ SQL Editor â†’ New Query
- **Table Editor:** Dashboard â†’ Table Editor
- **API Settings:** Dashboard â†’ Settings â†’ API
- **Logs:** Dashboard â†’ Database â†’ Logs

### Useful PostgreSQL Commands:
```sql
-- Check active connections
SELECT count(*) FROM pg_stat_activity;

-- View table sizes
SELECT pg_size_pretty(pg_total_relation_size('tasks'));

-- View all indexes
SELECT * FROM pg_indexes WHERE tablename = 'tasks';

-- Check if RLS is enabled
SELECT tablename, rowsecurity FROM pg_tables
WHERE schemaname = 'public';

-- View running queries
SELECT pid, query, state, query_start
FROM pg_stat_activity
WHERE state = 'active';
```

### Common Supabase Error Codes:
| Code | Meaning | Solution |
|------|---------|----------|
| `PGRST116` | No rows found | Return 404 |
| `23505` | Unique violation | Return 409 (Conflict) |
| `23503` | FK violation | Check referenced record |
| `42501` | Permission denied | Check RLS policies |
| `08006` | Connection failed | Retry or return 503 |

---

**ğŸ‰ After completing this guide, you'll have:**
- A robust database connection layer with health monitoring
- Proper error handling for all database failure scenarios
- Version-controlled migrations for schema changes
- Optimized queries with appropriate indexes
- Transaction support for complex multi-step operations
- Hands-on experience with PostgreSQL and Supabase internals!

**â¡ï¸ Next:** Move on to **5. ADVANCED_FEATURES.md** to build user-specific tasks, tags, subtasks, and real-time features!
